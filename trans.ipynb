{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ec55d3-58a3-4440-8f36-c74da2e6407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import chardet\n",
    "import os\n",
    "import re\n",
    "import whisper\n",
    "import torch\n",
    "from bs4 import BeautifulSoup\n",
    "from pydub import AudioSegment\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b25b299-0197-4ffb-b873-8c8879ff603f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_url_from_podcast(url):\n",
    "    \"\"\"\n",
    "    Extract audio URL and podcast title from an Apple Podcast page.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Failed to fetch the webpage. Status code: {response.status_code}\\nURL: {url}\")\n",
    "\n",
    "    # 自动检测编码\n",
    "    detected_encoding = chardet.detect(response.content)['encoding']\n",
    "    print(f\"Detected encoding: {detected_encoding}\")\n",
    "    if detected_encoding:\n",
    "        response.encoding = detected_encoding\n",
    "    else:\n",
    "        response.encoding = 'utf-8'  # 默认使用 utf-8 编码\n",
    "\n",
    "    # 打印前 500 个字符的 HTML 内容进行验证\n",
    "    #print(\"Fetched HTML content preview:\")\n",
    "    #print(response.text[:5000])  # 打印部分 HTML 内容\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find audio URL (MP3 or M4A)\n",
    "    audio_urls = re.findall(r'https://[^\\s^\"]+(?:\\.mp3|\\.m4a)', response.text)\n",
    "    if not audio_urls:\n",
    "        raise Exception(\"No audio URLs found on the page.\")\n",
    "    return audio_urls[-1], soup  # Return the last found URL and soup\n",
    "\n",
    "\n",
    "def get_podcast_title(soup):\n",
    "    \"\"\"\n",
    "    Extract the title of the podcast episode from the HTML soup.\n",
    "    \"\"\"\n",
    "    title_tag = soup.find('title')\n",
    "    if title_tag:\n",
    "        title = title_tag.text.strip()\n",
    "        # 清理多余的后缀\n",
    "        title = re.sub(r\" - .*Apple Podcasts.*\", \"\", title)\n",
    "        # 处理可能的编码问题\n",
    "        title = title.encode('latin1').decode('utf-8') if 'charset=iso' in str(soup) else title\n",
    "        return title\n",
    "    else:\n",
    "        return \"unknown_podcast\"\n",
    "\n",
    "\n",
    "def format_filename(title):\n",
    "    \"\"\"\n",
    "    Format the title to create a safe filename.\n",
    "    \"\"\"\n",
    "    title = re.sub(r'[^\\w\\-_\\. ]', '_', title)  # 替换特殊字符为 \"_\"\n",
    "    return title\n",
    "\n",
    "\n",
    "def download_audio_file(audio_url, title, output_folder=\"downloads\"):\n",
    "    \"\"\"\n",
    "    Download the audio file from a given URL and save it locally with the given title.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # 格式化标题为文件名\n",
    "    formatted_title = format_filename(title)\n",
    "    file_extension = os.path.splitext(urlparse(audio_url).path)[1]\n",
    "    output_path = os.path.join(output_folder, f\"{formatted_title}{file_extension}\")\n",
    "\n",
    "    # Stream and save the audio file\n",
    "    with requests.get(audio_url, stream=True) as response:\n",
    "        response.raise_for_status()\n",
    "        with open(output_path, \"wb\") as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "\n",
    "    return output_path\n",
    "\n",
    "\n",
    "def convert_audio_to_wav(input_file, title):\n",
    "    \"\"\"\n",
    "    Convert audio file (MP3/M4A) to WAV format and save it with the given title.\n",
    "    \"\"\"\n",
    "    formatted_title = format_filename(title)\n",
    "    output_file = os.path.join(os.path.dirname(input_file), f\"{formatted_title}.wav\")\n",
    "    \n",
    "    if input_file.lower().endswith(\".mp3\"):\n",
    "        audio = AudioSegment.from_mp3(input_file)\n",
    "    elif input_file.lower().endswith(\".m4a\"):\n",
    "        audio = AudioSegment.from_file(input_file, \"m4a\")\n",
    "    else:\n",
    "        raise Exception(\"Unsupported audio format. Only MP3 and M4A are supported.\")\n",
    "    \n",
    "    audio.export(output_file, format=\"wav\")\n",
    "    return output_file\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 交互式部分：提示用户输入 Apple Podcast 链接\n",
    "podcast_url = input(\"请输入 Apple Podcast 的链接: \")\n",
    "\n",
    "try:\n",
    "    # 1. 提取音频 URL 和 HTML 内容\n",
    "    audio_url, soup = get_audio_url_from_podcast(podcast_url)\n",
    "    print(f\"提取的音频 URL: {audio_url}\")\n",
    "\n",
    "    # 2. 提取标题\n",
    "    podcast_title = get_podcast_title(soup)\n",
    "    print(f\"提取的博客标题: {podcast_title}\")\n",
    "\n",
    "    # 3. 询问用户是否修改文件名\n",
    "    custom_title = input(f\"请输入文件名（按 n 使用默认标题“{podcast_title}”）: \").strip()\n",
    "    if custom_title.lower() == 'n' or not custom_title:\n",
    "        custom_title = podcast_title  # 使用默认值\n",
    "    print(f\"最终使用的文件名: {custom_title}\")\n",
    "\n",
    "    # 4. 下载音频文件\n",
    "    downloaded_file = download_audio_file(audio_url, custom_title)\n",
    "    print(f\"音频文件已下载: {downloaded_file}\")\n",
    "\n",
    "    # 5. 转换为 WAV 格式\n",
    "    wav_file = convert_audio_to_wav(downloaded_file, custom_title)\n",
    "    print(f\"音频文件已转换为 WAV 格式: {wav_file}\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"处理过程中发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da549e3e-f169-44b4-abc4-ff00d6fd85a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d2d39ee-f025-448a-8d8a-c3b793ab7cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Whisper model: large-v3...\n",
      "Model large-v3 loaded successfully.\n",
      "Transcribing audio: downloads/2月份月度对话.wav...\n",
      "Releasing GPU memory...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 68\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# 2. 转录音频\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m transcription_result \u001b[38;5;241m=\u001b[39m \u001b[43mtranscribe_audio_v3\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwav_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;66;03m# 3. 保存转录结果为 SRT 文件\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m, in \u001b[0;36mtranscribe_audio_v3\u001b[0;34m(model, audio_path, task, language, verbose)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscribing audio: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 19\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranscribe\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTranscription completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/whisper/transcribe.py:295\u001b[0m, in \u001b[0;36mtranscribe\u001b[0;34m(model, audio, verbose, temperature, compression_ratio_threshold, logprob_threshold, no_speech_threshold, condition_on_previous_text, initial_prompt, carry_initial_prompt, word_timestamps, prepend_punctuations, append_punctuations, clip_timestamps, hallucination_silence_threshold, **decode_options)\u001b[0m\n\u001b[1;32m    293\u001b[0m     decode_options[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_tokens[prompt_reset_since:]\n\u001b[0;32m--> 295\u001b[0m result: DecodingResult \u001b[38;5;241m=\u001b[39m \u001b[43mdecode_with_fallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel_segment\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m tokens \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(result\u001b[38;5;241m.\u001b[39mtokens)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/whisper/transcribe.py:201\u001b[0m, in \u001b[0;36mtranscribe.<locals>.decode_with_fallback\u001b[0;34m(segment)\u001b[0m\n\u001b[1;32m    200\u001b[0m options \u001b[38;5;241m=\u001b[39m DecodingOptions(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, temperature\u001b[38;5;241m=\u001b[39mt)\n\u001b[0;32m--> 201\u001b[0m decode_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m needs_fallback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/whisper/decoding.py:824\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    822\u001b[0m     options \u001b[38;5;241m=\u001b[39m replace(options, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 824\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mDecodingTask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m single \u001b[38;5;28;01melse\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/whisper/decoding.py:737\u001b[0m, in \u001b[0;36mDecodingTask.run\u001b[0;34m(self, mel)\u001b[0m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;66;03m# call the main sampling loop\u001b[39;00m\n\u001b[0;32m--> 737\u001b[0m tokens, sum_logprobs, no_speech_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_main_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# reshape the tensors to have (n_audio, n_group) as the first two dimensions\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/whisper/decoding.py:700\u001b[0m, in \u001b[0;36mDecodingTask._main_loop\u001b[0;34m(self, audio_features, tokens)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m logit_filter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogit_filters:\n\u001b[0;32m--> 700\u001b[0m     \u001b[43mlogit_filter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# expand the tokens tensor with the selected next tokens\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 82\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReleasing GPU memory...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model  \u001b[38;5;66;03m# 删除模型对象\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 释放未使用的显存\u001b[39;00m\n\u001b[1;32m     83\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()  \u001b[38;5;66;03m# 强制进行垃圾回收\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU memory released.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/torch/cuda/memory.py:159\u001b[0m, in \u001b[0;36mempty_cache\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Releases all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m`nvidia-smi`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[0;32m--> 159\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "import gc\n",
    "\n",
    "def load_whisper_model_v3(model_name=\"large-v3\"):\n",
    "    \"\"\"\n",
    "    Load the Whisper model (large-v3) from Hugging Face.\n",
    "    \"\"\"\n",
    "    print(f\"Loading Whisper model: {model_name}...\")\n",
    "    model = whisper.load_model(model_name)\n",
    "    print(f\"Model {model_name} loaded successfully.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def transcribe_audio_v3(model, audio_path, task=\"transcribe\", language=None,verbose=True):\n",
    "    \"\"\"\n",
    "    Transcribe audio using Whisper model (large-v3).\n",
    "    \"\"\"\n",
    "    print(f\"Transcribing audio: {audio_path}...\")\n",
    "    result = model.transcribe(audio_path, task=task, language=language, verbose=verbose)#增加了最后一个verbose\n",
    "    print(\"Transcription completed.\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def save_transcription_as_srt_v3(transcription, audio_path):\n",
    "    \"\"\"\n",
    "    Save transcription result as SRT file.\n",
    "    \"\"\"\n",
    "    srt_file_path = os.path.splitext(audio_path)[0] + \".srt\"\n",
    "    with open(srt_file_path, \"w\", encoding=\"utf-8\") as srt_file:\n",
    "        for segment in transcription['segments']:\n",
    "            start = segment['start']\n",
    "            end = segment['end']\n",
    "            text = segment['text']\n",
    "            # Write to SRT format\n",
    "            srt_file.write(f\"{segment['id'] + 1}\\n\")\n",
    "            srt_file.write(f\"{format_timestamp(start)} --> {format_timestamp(end)}\\n\")\n",
    "            srt_file.write(f\"{text}\\n\\n\")\n",
    "    print(f\"Transcription saved as SRT: {srt_file_path}\")\n",
    "    return srt_file_path\n",
    "\n",
    "\n",
    "def format_timestamp(seconds):\n",
    "    \"\"\"\n",
    "    Format timestamp for SRT file.\n",
    "    \"\"\"\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = seconds % 60\n",
    "    milliseconds = int((seconds - int(seconds)) * 1000)\n",
    "    return f\"{hours:02}:{minutes:02}:{int(seconds):02},{milliseconds:03}\"\n",
    "\n",
    "\n",
    "\n",
    "# 主程序：模块二集成\n",
    "if __name__ == \"__main__\":\n",
    "    # 假设模块一已经完成，直接获取 WAV 文件路径\n",
    "    wav_file_path = wav_file  # 上一模块生成的结果\n",
    "\n",
    "    # 确保文件存在\n",
    "    if not wav_file_path or not os.path.exists(wav_file_path):\n",
    "        print(f\"错误：音频文件 {wav_file_path} 不存在！请确保模块一已正确运行。\")\n",
    "    else:\n",
    "        try:\n",
    "            # 1. 加载 Whisper large-v3 模型\n",
    "            model = load_whisper_model_v3(\"large-v3\")\n",
    "\n",
    "            # 2. 转录音频\n",
    "            transcription_result = transcribe_audio_v3(model, wav_file_path)\n",
    "\n",
    "            # 3. 保存转录结果为 SRT 文件\n",
    "            srt_file_path = save_transcription_as_srt_v3(transcription_result, wav_file_path)\n",
    "\n",
    "            print(f\"转录完成！字幕文件保存在: {srt_file_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"处理过程中发生错误: {e}\")\n",
    "\n",
    "        finally:\n",
    "            # 显存释放\n",
    "            print(\"Releasing GPU memory...\")\n",
    "            del model  # 删除模型对象\n",
    "            torch.cuda.empty_cache()  # 释放未使用的显存\n",
    "            gc.collect()  # 强制进行垃圾回收\n",
    "            print(\"GPU memory released.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c660ca-40a7-4611-9db6-26b83fb29efc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pro1",
   "language": "python",
   "name": "pro1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
